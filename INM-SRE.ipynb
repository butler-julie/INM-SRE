{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "645fa82b-40e5-4786-92c0-369a55e3aad7",
   "metadata": {},
   "source": [
    "# Coupled Cluster Calculations of Infinite Nuclear Matter in the Complete Basis Limit Using Bayesian Machine Learning\n",
    "## Source Code\n",
    "\n",
    "Date Created: August 17, 2024\n",
    "\n",
    "Last Modified: August 17, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c70a744-2127-41c7-b4ea-7f6aa12f4bc6",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bd288dc-77ff-4656-bc6e-650c4899d562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.17 ms, sys: 8.33 ms, total: 17.5 ms\n",
      "Wall time: 18.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "##############################\n",
    "##          IMPORTS         ##\n",
    "##############################\n",
    "# THIRD PARTY IMPORTS\n",
    "# For arrays\n",
    "import numpy as np\n",
    "# For importing the data set\n",
    "import pandas as pd\n",
    "# For graphing\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from sklearn.gaussian_process.kernels import ConstantKernel, WhiteKernel, RationalQuadratic\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor as GP\n",
    "\n",
    "##############################\n",
    "##        DIRECTORIES       ##\n",
    "##############################\n",
    "# Directories to find data files and save images\n",
    "data_dir = 'raw_data/'\n",
    "images_dir = 'img/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e60f99c-78fe-4c78-997f-d018ec036acc",
   "metadata": {},
   "source": [
    "## Importing and Formatting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64526a46-f36c-4ce5-88b3-a16812035621",
   "metadata": {},
   "source": [
    "### CCD PNM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ec0def9-f777-4ccd-8bc1-71a9d877386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccd_pnm_data_dir = data_dir+\"CCD_PNM/\"\n",
    "ccd_pnm_data = []\n",
    "for file in glob.glob(ccd_pnm_data_dir+\"*.csv\"):\n",
    "    df = pd.read_csv(file)\n",
    "    ccd_pnm_data.append(df.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4c909d-c5ae-4e7c-8bc4-56f5033e2b7d",
   "metadata": {},
   "source": [
    "### CCD SNM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4685625-de70-4437-adc7-5e4d639bbad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccd_snm_data_dir = data_dir+\"CCD_SNM/\"\n",
    "ccd_snm_data = []\n",
    "for file in glob.glob(ccd_snm_data_dir+\"*.csv\"):\n",
    "    df = pd.read_csv(file)\n",
    "    ccd_snm_data.append(df.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680ca010-4f4a-4e14-b5c2-b42c47e1aac5",
   "metadata": {},
   "source": [
    "### CCD(T) PNM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7ea37a1-7e1e-4146-8203-19537cd06cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccdt_pert_pnm_data_dir = data_dir+\"CCDT_Pert_PNM/\"\n",
    "ccdt_pert_pnm_data = []\n",
    "for file in glob.glob(ccdt_pert_pnm_data_dir+\"*.csv\"):\n",
    "    df = pd.read_csv(file)\n",
    "    ccdt_pert_pnm_data.append(df.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a48038-0d18-488b-bdff-cb6ff2f234ac",
   "metadata": {},
   "source": [
    "### CCD(T) SNM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bb4eaa2-bd15-4e9a-88bf-cdfeb62bc932",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccdt_pert_snm_data_dir = data_dir+\"CCDT_Pert_SNM/\"\n",
    "ccdt_pert_snm_data = []\n",
    "for file in glob.glob(ccdt_pert_snm_data_dir+\"*.csv\"):\n",
    "    df = pd.read_csv(file)\n",
    "    ccdt_pert_snm_data.append(df.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b288fc8-e0f2-492a-ac28-7e38fd0d07c4",
   "metadata": {},
   "source": [
    "## Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aeb34f5a-21b2-43ef-9cd0-ac24548968bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "##      GET STATES DICT     ##\n",
    "##############################    \n",
    "def get_states_dict ():\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        None.\n",
    "    Returns:\n",
    "        states_dict (a dictionary): the conversion between shell number and number of \n",
    "            single particle states.\n",
    "    Dictionary thats converts between number of shells to number of single particle states\n",
    "    for the first 178 shells.  \n",
    "    \"\"\"\n",
    "    states_dict = {\n",
    "        1:2, 2:14, 3:38, 4:54, 5:66, 6:114, 7:162, 8:186, 9:246, 10:294, \n",
    "        11:342, 12:358, 13:406, 14:502, 15:514, 16:610, 17:682, 18:730, \n",
    "        19:778, 20:874, 21:922, 22:970, 23:1030, 24:1174, 25:1238, 26:1382, \n",
    "        27:1478, 28:1502,29:1598, 30:1694, 31:1790, 32:1850, 33:1898, \n",
    "        34:2042, 35:2090, 36:2282, 37:2378, 38:2426, 39:2474, 40:2618, \n",
    "        41:2714, 42:2730, 43:2838, 44:3006, 45:3102, 46:3150, 47:3294, \n",
    "        48:3486, 49:3582, 50:3678, 51:3726, 52:3870, 53:4014, 54:4206, \n",
    "        55:4218, 56:4410, 57:4602, 58:4650, 59:4746,  60:4938, 61:5034, \n",
    "        62:5106, 63:5202, 64:5442, 65:5554, 66:5602, 67:5794, 68:5890,\n",
    "        69:5938, 70:6142, 71:6238, 72:6382, 73:6478, 74:6574, 75:6814,\n",
    "        76:6862, 77:7150, 78:7390, 79:7486, 80:7582, 81:7774, 82:7822,\n",
    "        83:7918, 84:8134, 85:8278, 86:8338, 87:8674, 88:8770, 89:8914,\n",
    "        90:9106 ,91:9250, 92:9394, 93:9458, 94:9602, 95:9890, 96:10082,\n",
    "        97:10274, 98:10370, 99:10514, 100:10754, 101:10898, 102:10994,\n",
    "        103:11138, 104:11330, 105:11378, 106:11618, 107:11810, 108:11834,\n",
    "        109:12074, 110:12122, 111:12266, 112:12362, 113:12458, 114:12698,\n",
    "        115:12794, 116:12938, 117:13034, 118:13130, 119:13226, 120:13322,\n",
    "        121:13418, 122:13466, 123:13610, 124:13802, 125:13818, 126:14058,\n",
    "        127:14202, 128:14298, 129:14490, 130:14586, 131:14682, 132:14778,\n",
    "        133:14970, 134:15042, 135:15090, 136:15186, 137:15378, 138:15522,\n",
    "        139:15618, 140:15714, 141:15762, 142:15810, 143:15906, 144:16002,\n",
    "        145:16050, 146:16098, 147:16146, 148:16242, 149:16386, 150:16482,\n",
    "        151:16674, 152:16722, 153:16818, 154:16914, 155:16930, 156:17026,\n",
    "        157:17122, 158:17218, 159:17338, 160:17386, 161:17434, 162:17530,\n",
    "        163:17626, 164:17674, 165:17770, 166:17818, 167:17914, 168:17962,\n",
    "        169:18010, 170:18058, 171:18154, 172:18202, 173:18218, 174:18314,\n",
    "        175:18362, 176:18410, 177:18458, 178:18506}\n",
    "        \n",
    "    return states_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fe65d2-c640-4870-ba1a-dcb72447a29b",
   "metadata": {},
   "source": [
    "### Left"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4323bd70-ca90-4cfa-9103-2d7bf547ab3a",
   "metadata": {},
   "source": [
    "### Right"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef92190-7f48-44b7-9473-4cf5e0a63e21",
   "metadata": {},
   "source": [
    "## Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be29e945-7866-48b5-ab2b-651cf5c31981",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "##  FORMAT SEQUENTIAL DATA  ##\n",
    "##############################\n",
    "def format_sequential_data (y, seq=2):\n",
    "    \"\"\"\n",
    "        Inputs:\n",
    "            y (a list or NumPy array): the y values of a data set\n",
    "            seq (an int): the length of the sequence.  Default value is 2\n",
    "        Returns:\n",
    "            inputs (a list): the inputs for a machine learning model using \n",
    "                sequential data formatting\n",
    "            outputs (a list): the outputs for a machine learning model using\n",
    "                sequential data formatting              \n",
    "        Formats a given list or array in sequential formatting using the \n",
    "        given sequence lenght.  Default sequence length is two.\n",
    "\n",
    "        Explanation of sequential formatting:\n",
    "        Typically data points of the form (x,y) are used to train a machine\n",
    "        learning model.  This teaches the model the relationship between the\n",
    "        x data and the y data in the training range.  This model works well \n",
    "        for interpolation, but not so well for extrapolation.  A better data\n",
    "        model for extrapolation would be one that learns the patterns in the y\n",
    "        data to better guess what y value should come next.  Therefore, this \n",
    "        method formats the data in a sequential pattern so that the points are\n",
    "        of the form ((y1, y2, ..., yn), yn+1) where n is the lenght of the \n",
    "        sequence (seq).\n",
    "    \"\"\"\n",
    "    # Make sure seq is an int\n",
    "    assert isinstance(seq, int)\n",
    "    # Set up the input and output lists\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    # Cycle through the whole y list/array and separate the points into \n",
    "    # sequential format\n",
    "    for i in range(0, len(y)-seq):\n",
    "        inputs.append(y[i:i+seq])\n",
    "        outputs.append(y[i+seq])\n",
    "    # Return the input and output lists.  NOTE: the data type of the return \n",
    "    # values is LIST\n",
    "    return inputs, outputs  \n",
    "####################################\n",
    "## SEQUENTIAL EXTRAPOLATE SKLEARN ##\n",
    "####################################\n",
    "def sequential_extrapolate_sklearn (R, y_train, num_points, seq):\n",
    "    \"\"\"\n",
    "        Inputs:\n",
    "            R (an object): A trained Scikit-Learn regression model\n",
    "            y_train (a list): the y component of the training data set, unformatted\n",
    "            num_points (an int): the number of points to be in the extrapolated data set\n",
    "            seq (an int): the SRE length of sequence that R was trained with\n",
    "        Returns:\n",
    "            y_test (a list): the extrapolated data set\n",
    "            y_std (a list): the uncertainity on each point in the extrapoalted set\n",
    "        Performs SRE using a trained Scikit-Learn regression model.\n",
    "    \"\"\"\n",
    "    # Make sure inputs are of the proper type\n",
    "    assert isinstance(num_points, int)\n",
    "    assert isinstance(seq, int)\n",
    "\n",
    "    # Add the training data to the extrapolated data set and no uncertainities for the\n",
    "    # training data\n",
    "    y_test = y_train.copy()\n",
    "    y_std = np.zeros(len(y_train)).tolist()\n",
    "\n",
    "    # Extrapolate until enough data points have been predicted\n",
    "    while len(y_test) < num_points:\n",
    "        next_test = y_test[-seq:]\n",
    "        point,std = R.predict([next_test],return_std=True)\n",
    "        y_test.append(point[0])\n",
    "        y_std.append(std[0])\n",
    "\n",
    "    # Return the predicted data set and uncertainities\n",
    "    return y_test,y_std    \n",
    "def perform_extrapolations (data_sets,dim=4, start_dim=1, seq=1, n = 4,non_seq=False):\n",
    "    results = []\n",
    "    # For each data set\n",
    "    for A in data_sets:\n",
    "        # Separate the columns\n",
    "        shells = A[:,0]\n",
    "        particles = A[:,1]\n",
    "        matter_type = A[:,2]\n",
    "        density = A[:,3]\n",
    "        reference_E = A[:,4]\n",
    "        mbpt2_E = A[:,5]\n",
    "        ccd_E = A[:,6]\n",
    "        ccd_times = A[:,7]\n",
    "        # Calculate the correlation energies (total not per particle)\n",
    "        mbpt2_correlation_E = (mbpt2_E - reference_E)*particles[0]\n",
    "        ccd_correlation_E = (ccd_E - reference_E)*particles[0]\n",
    "        # Seperate the final values (the test data), and the training data\n",
    "        final_cc = ccd_correlation_E[-1]\n",
    "        final_mbpt =mbpt2_correlation_E[-1]\n",
    "        cc_seq = ccd_correlation_E[start_dim:dim]\n",
    "        mbpt_seq = mbpt2_correlation_E[start_dim:dim]\n",
    "        # Separate the specified points for the training data, without the first one\n",
    "        # which would yield 0/0 with division\n",
    "        training_data = cc_seq/mbpt_seq\n",
    "        training_data = training_data.tolist()\n",
    "        # Format the training data in sequential series formatting\n",
    "        x_train, y_train = format_sequential_data (training_data, seq=seq)\n",
    "        # Set up kernel function\n",
    "        kernel = ConstantKernel()*RationalQuadratic()+WhiteKernel()\n",
    "        # Set up Gaussian Process algorithm and train it\n",
    "        R = GP(kernel=kernel, alpha=np.std(training_data)**n,n_restarts_optimizer=5)\n",
    "        #R = BayesianRidge(n_iter=10000,tol=1e-5)\n",
    "        R.fit(x_train, y_train)\n",
    "        # Feed the trained GP algorithm and data into the SRE method\n",
    "        ypred,ystd = sequential_extrapolate_sklearn(R, training_data, 50, seq=seq)\n",
    "        # Separate the last prediction as the final converged slope\n",
    "        final_slope = ypred[-1]\n",
    "        # Predict the CC correlation energy at the long range point\n",
    "        cc_prediction = final_slope*final_mbpt\n",
    "        # Calculate the uncertainity on the CC correlation energy prediction\n",
    "        slope_uncertainity = ystd[-1]\n",
    "        #print(slope_uncertainity)\n",
    "        cc_prediction_uncertainity = slope_uncertainity*final_mbpt\n",
    "        results.append([cc_prediction, final_cc, np.sum(ccd_times[start_dim:dim]), ccd_times[-1], ccd_correlation_E[dim-1], cc_prediction_uncertainity])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdc3635-2267-4100-87c4-fca6dfcd77aa",
   "metadata": {},
   "source": [
    "### Left"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a63629-b68a-46d9-85a4-4af94460177f",
   "metadata": {},
   "source": [
    "### Right"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9122988-061d-4e5b-b17d-46f069d5eae7",
   "metadata": {},
   "source": [
    "## Figure 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfa4bc3-2dcb-496e-a410-e8d27f610cea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
